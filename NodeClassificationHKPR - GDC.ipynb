{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zgNRxCONcpBh",
        "outputId": "5232f1e5-e6b7-4e48-b766-edf5291e19d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/torch-2.3/repo.html\n",
            "Requirement already satisfied: dgl in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dgl) (1.13.0)\n",
            "Requirement already satisfied: networkx>=2.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dgl) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dgl) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\taneem\\appdata\\roaming\\python\\python312\\site-packages (from dgl) (5.9.8)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dgl) (0.8.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dgl) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->dgl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->dgl) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: torch>=2 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchdata>=0.5.0->dgl) (2.3.0+cu121)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->dgl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->dgl) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (2024.3.1)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (2021.4.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2->torchdata>=0.5.0->dgl) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2->torchdata>=0.5.0->dgl) (2021.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: labml-nn in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.137)\n",
            "Requirement already satisfied: labml==0.4.168 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml-nn) (0.4.168)\n",
            "Requirement already satisfied: labml-helpers==0.4.89 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml-nn) (0.4.89)\n",
            "Requirement already satisfied: torch in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml-nn) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchtext in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml-nn) (0.18.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml-nn) (0.18.0)\n",
            "Requirement already satisfied: einops in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml-nn) (0.8.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml-nn) (1.26.4)\n",
            "Requirement already satisfied: fairscale in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml-nn) (0.4.13)\n",
            "Requirement already satisfied: gitpython in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml==0.4.168->labml-nn) (3.1.43)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from labml==0.4.168->labml-nn) (6.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->labml-nn) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->labml-nn) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->labml-nn) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->labml-nn) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->labml-nn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->labml-nn) (2024.3.1)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->labml-nn) (2021.4.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext->labml-nn) (4.66.4)\n",
            "Requirement already satisfied: requests in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext->labml-nn) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->labml-nn) (10.2.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->labml-nn) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->labml-nn) (2021.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython->labml==0.4.168->labml-nn) (4.0.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->labml-nn) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext->labml-nn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext->labml-nn) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext->labml-nn) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext->labml-nn) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch->labml-nn) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->torchtext->labml-nn) (0.4.6)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->labml==0.4.168->labml-nn) (5.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/repo.html\n",
        "%pip install labml-nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydantic in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.9.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\taneem\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (4.11.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Taneem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchdata\\datapipes\\__init__.py:18: UserWarning: \n",
            "################################################################################\n",
            "WARNING!\n",
            "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
            "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
            "to learn more and leave feedback.\n",
            "################################################################################\n",
            "\n",
            "  deprecation_warning()\n",
            "c:\\Users\\Taneem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import dgl\n",
        "import dgl.sparse as dglsp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse.linalg import expm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9Fitk5OIy8Zw",
        "outputId": "6db5fcd9-cf07-4bdf-dafe-23609ea44851"
      },
      "outputs": [],
      "source": [
        "class LinearNeuralNetwork(nn.Module):\n",
        "    def __init__(self, nfeat, nclass, bias=True):\n",
        "        super(LinearNeuralNetwork, self).__init__()\n",
        "        self.W = nn.Linear(nfeat, nclass, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.W(x)\n",
        "\n",
        "\n",
        "def symmetric_normalize_adjacency(graph):\n",
        "    \"\"\"Symmetric normalize graph adjacency matrix.\"\"\"\n",
        "    indices = torch.stack(graph.edges())\n",
        "    n = graph.num_nodes()\n",
        "    adj = dglsp.spmatrix(indices, shape=(n, n))\n",
        "    deg_invsqrt = dglsp.diag(adj.sum(0)) ** -0.5\n",
        "    return deg_invsqrt @ adj @ deg_invsqrt\n",
        "\n",
        "\n",
        "def model_test(model, embeds):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(embeds)\n",
        "        pred = output.argmax(dim=-1)\n",
        "        test_mask, tv_mask = model.test_mask, model.tv_mask\n",
        "        loss_tv = F.mse_loss(output[tv_mask], model.label_one_hot[tv_mask])\n",
        "    accs = []\n",
        "    for mask in [tv_mask, test_mask]:\n",
        "        accs.append(\n",
        "            float((pred[mask] == model.label[mask]).sum() / mask.sum()))\n",
        "    return loss_tv.item(), accs[0], accs[1], pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "q_p4Vz1ac-v_",
        "outputId": "3050a0b8-2638-4d97-9ca6-b775f4b9e43c"
      },
      "outputs": [],
      "source": [
        "class OGC(nn.Module):\n",
        "    def __init__(self, graph):\n",
        "        super(OGC, self).__init__()\n",
        "        self.linear_clf = LinearNeuralNetwork(\n",
        "            nfeat=graph.ndata[\"feat\"].shape[1],\n",
        "            nclass=graph.ndata[\"label\"].max().item() + 1,\n",
        "            bias=False,\n",
        "        )\n",
        "\n",
        "        self.label = graph.ndata[\"label\"]\n",
        "        self.label_one_hot = F.one_hot(graph.ndata[\"label\"]).float()\n",
        "        # LIM trick, else use both train and val set to construct this matrix.\n",
        "        self.label_idx_mat = dglsp.diag(graph.ndata[\"train_mask\"]).float()\n",
        "\n",
        "        self.test_mask = graph.ndata[\"test_mask\"]\n",
        "        self.tv_mask = graph.ndata[\"train_mask\"] + graph.ndata[\"val_mask\"]\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_clf(x)\n",
        "\n",
        "    def update_embeds(self, embeds, lazy_adj, args):\n",
        "        \"\"\"Update classifier's weight by training a linear supervised model.\"\"\"\n",
        "        pred_label = self(embeds).data\n",
        "        clf_weight = self.linear_clf.W.weight.data\n",
        "\n",
        "        # Update the smoothness loss via LGC.\n",
        "        embeds = dglsp.spmm(lazy_adj, embeds)\n",
        "\n",
        "        # Update the supervised loss via SEB.\n",
        "        deriv_sup = 2 * dglsp.matmul(\n",
        "            dglsp.spmm(self.label_idx_mat, -self.label_one_hot + pred_label),\n",
        "            clf_weight,\n",
        "        )\n",
        "        embeds = embeds - args.lr_sup * deriv_sup\n",
        "\n",
        "        args.lr_sup = args.lr_sup * args.decline\n",
        "        return embeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "WVU5dTHRxtne",
        "outputId": "5580a423-927b-42b4-d027-fc62e391b398"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import time\n",
        "\n",
        "import dgl.sparse as dglsp\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from dgl import AddSelfLoop\n",
        "from dgl.data import CiteseerGraphDataset\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args([])\n",
        "args.dataset = \"citeseer\"\n",
        "args.decline = 0.9\n",
        "args.lr_sup = 0.001\n",
        "args.lr_clf = 0.5\n",
        "args.beta = 0.1\n",
        "args.max_sim_rate = 0.995\n",
        "args.max_patience = 2\n",
        "args.device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ScUDZ2Gjzw8z"
      },
      "outputs": [],
      "source": [
        "def train(model, embeds, lazy_adj, args):\n",
        "    patience = 0\n",
        "    _, _, last_acc, last_output = model_test(model, embeds)\n",
        "\n",
        "    tv_mask = model.tv_mask\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr_clf)\n",
        "\n",
        "    for i in range(64):\n",
        "        model.train()\n",
        "        output = model(embeds)\n",
        "        loss_tv = F.mse_loss(\n",
        "            output[tv_mask], model.label_one_hot[tv_mask], reduction=\"sum\"\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        loss_tv.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Updating node embeds by LGC and SEB jointly.\n",
        "        embeds = model.update_embeds(embeds, lazy_adj, args)\n",
        "\n",
        "        loss_tv, acc_tv, acc_test, pred = model_test(model, embeds)\n",
        "        print(\n",
        "            \"epoch {} loss_tv {:.4f} acc_tv {:.4f} acc_test {:.4f}\".format(\n",
        "                i + 1, loss_tv, acc_tv, acc_test\n",
        "            )\n",
        "        )\n",
        "\n",
        "        sim_rate = float(int((pred == last_output).sum()) / int(pred.shape[0]))\n",
        "        if sim_rate > args.max_sim_rate:\n",
        "            patience += 1\n",
        "            if patience > args.max_patience:\n",
        "                break\n",
        "        last_acc = acc_test\n",
        "        last_output = pred\n",
        "    return last_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Feb 22 10:38:37 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 546.33                 Driver Version: 546.33       CUDA Version: 12.3     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1650 Ti   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   52C    P0              12W /  50W |     99MiB /  4096MiB |     19%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A     17624    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "3bb63e36125742e782aca29a37a4574e",
            "83fd1cc79ffb4e358da3a4e2cdbf98dc",
            "056b821b52f549719e4b49583a1aad59",
            "62a93d8902634a0ca9f4dd35b1a7713a",
            "18c282ed6e7348c1bdeebc7dc031278a",
            "b2cd39f4ccda4efc8816a02337945955",
            "e43d5bbcbbe04b9ba7862febb04088d3",
            "69f198b8b1c0460985761f8477fac1ef",
            "f74db49c87c14c26b6045c893d1bfb64",
            "d1fd7c0036044bd096bbc87706177432",
            "8c3caa59addd4042be54ce85c0849b5f"
          ]
        },
        "id": "j02-1yeXIP8F",
        "outputId": "ace01551-9aed-48ee-dca2-f79203a81c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ],
      "source": [
        "transform = AddSelfLoop()\n",
        "data = CiteseerGraphDataset(transform=transform)\n",
        "graph = data[0].to(args.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlHds92MImw2",
        "outputId": "0fdb14db-40c5-4adb-a945-b73041e9374f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([False])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.has_edges_between([0], [1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_heat(adj_matrix: sp.csr_matrix, t: float = 5.0, k: int = 128):\n",
        "    \"\"\"Adapted from GDC's diffusion.py - computes heat kernel diffusion matrix\"\"\"\n",
        "    n = adj_matrix.shape[0]\n",
        "    L = sp.eye(n, format=\"csr\") - adj_matrix  # Unnormalized Laplacian\n",
        "    heat = sp.eye(n, format=\"csr\")\n",
        "    L_power = sp.eye(n, format=\"csr\")\n",
        "    fact_t = 1.0\n",
        "\n",
        "    for i in range(1, k):\n",
        "        L_power = L_power.dot(L)\n",
        "        fact_t *= t / i\n",
        "        heat -= fact_t * L_power\n",
        "\n",
        "    return heat\n",
        "\n",
        "# 2. Compute Heat Kernel PageRank score by GDC\n",
        "\n",
        "\n",
        "def compute_gdc_hkpr(graph, t=5.0, k=128):\n",
        "    \"\"\"Compute HKPR scores using GDC's approximation\"\"\"\n",
        "    # Get symmetric normalized adjacency in SciPy format\n",
        "    indices = torch.stack(graph.edges())\n",
        "    n = graph.num_nodes()\n",
        "    adj = sp.coo_matrix(\n",
        "        (\n",
        "            np.ones(indices.shape[1]),  # Data (all ones for unweighted edges)\n",
        "            (indices[0].numpy(), indices[1].numpy())  # Row and column indices\n",
        "        ),\n",
        "        shape=(n, n)\n",
        "    ).tocsr()  # Convert to CSR format for efficient computations\n",
        "\n",
        "    # Compute heat kernel matrix\n",
        "    heat = get_heat(adj, t=t, k=k)\n",
        "\n",
        "    # Compute HKPR scores (uniform personalization)\n",
        "    s = np.ones(n) / n  # Uniform starting vector\n",
        "    hkpr_scores = heat.dot(s)  # Matrix-vector multiplication\n",
        "\n",
        "    return torch.tensor(hkpr_scores, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.5520e-16, 1.1552e-04, 1.5520e-16,  ..., 5.8693e-04, 1.5520e-16,\n",
            "        1.5806e-08])\n"
          ]
        }
      ],
      "source": [
        "# Compute HKPR scores using GDC's method\n",
        "hkpr_scores = compute_gdc_hkpr(graph, t=3.0, k=64).to(args.device)\n",
        "hkpr_scores /= hkpr_scores.sum()  # Normalize\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(hkpr_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NnJt9F8zGAj",
        "outputId": "9205525e-d9b3-4952-b3fa-4016050529d5"
      },
      "outputs": [],
      "source": [
        "# Create diagonal matrix from HKPR scores\n",
        "hkpr_diag = dglsp.diag(hkpr_scores)\n",
        "\n",
        "# Symmetric normalized adjacency (DGL format)\n",
        "adj = symmetric_normalize_adjacency(graph)\n",
        "\n",
        "# Build lazy adjacency matrix with HKPR teleportation\n",
        "lazy_adj = dglsp.add((1 - args.beta) * hkpr_diag,\n",
        "                     args.beta * adj).to(args.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HZdqnLtuosuc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Parameters: 22218\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model = OGC(graph).to(args.device)\n",
        "print(f\"Model Parameters: {sum(p.numel() for p in model.parameters())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ZGP9yYeVz0Zt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 loss_tv 0.1484 acc_tv 0.8758 acc_test 0.7660\n",
            "epoch 2 loss_tv 0.1647 acc_tv 0.8694 acc_test 0.7740\n",
            "epoch 3 loss_tv 0.1665 acc_tv 0.8581 acc_test 0.7680\n",
            "epoch 4 loss_tv 0.1666 acc_tv 0.8468 acc_test 0.7700\n",
            "epoch 5 loss_tv 0.1667 acc_tv 0.8387 acc_test 0.7650\n",
            "epoch 6 loss_tv 0.1667 acc_tv 0.8355 acc_test 0.7620\n",
            "epoch 7 loss_tv 0.1667 acc_tv 0.8306 acc_test 0.7600\n",
            "epoch 8 loss_tv 0.1667 acc_tv 0.8226 acc_test 0.7570\n",
            "epoch 9 loss_tv 0.1667 acc_tv 0.8177 acc_test 0.7560\n",
            "epoch 10 loss_tv 0.1667 acc_tv 0.8145 acc_test 0.7540\n",
            "epoch 11 loss_tv 0.1667 acc_tv 0.8097 acc_test 0.7530\n",
            "epoch 12 loss_tv 0.1667 acc_tv 0.8097 acc_test 0.7520\n",
            "epoch 13 loss_tv 0.1667 acc_tv 0.8081 acc_test 0.7520\n",
            "Test Acc: 0.7520\n",
            "Total Time: 1.7774\n"
          ]
        }
      ],
      "source": [
        "features = graph.ndata[\"feat\"]\n",
        "start_time = time.time()\n",
        "res = train(model, features, lazy_adj, args)\n",
        "time_tot = time.time() - start_time\n",
        "\n",
        "print(f\"Test Acc: {res:.4f}\")\n",
        "print(f\"Total Time: {time_tot:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "056b821b52f549719e4b49583a1aad59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f198b8b1c0460985761f8477fac1ef",
            "max": 238901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f74db49c87c14c26b6045c893d1bfb64",
            "value": 238901
          }
        },
        "18c282ed6e7348c1bdeebc7dc031278a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb63e36125742e782aca29a37a4574e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83fd1cc79ffb4e358da3a4e2cdbf98dc",
              "IPY_MODEL_056b821b52f549719e4b49583a1aad59",
              "IPY_MODEL_62a93d8902634a0ca9f4dd35b1a7713a"
            ],
            "layout": "IPY_MODEL_18c282ed6e7348c1bdeebc7dc031278a"
          }
        },
        "62a93d8902634a0ca9f4dd35b1a7713a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1fd7c0036044bd096bbc87706177432",
            "placeholder": "​",
            "style": "IPY_MODEL_8c3caa59addd4042be54ce85c0849b5f",
            "value": " 239k/239k [00:00&lt;00:00, 3.37MB/s]"
          }
        },
        "69f198b8b1c0460985761f8477fac1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83fd1cc79ffb4e358da3a4e2cdbf98dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2cd39f4ccda4efc8816a02337945955",
            "placeholder": "​",
            "style": "IPY_MODEL_e43d5bbcbbe04b9ba7862febb04088d3",
            "value": "/root/.dgl/citeseer.zip: 100%"
          }
        },
        "8c3caa59addd4042be54ce85c0849b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2cd39f4ccda4efc8816a02337945955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1fd7c0036044bd096bbc87706177432": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e43d5bbcbbe04b9ba7862febb04088d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f74db49c87c14c26b6045c893d1bfb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
